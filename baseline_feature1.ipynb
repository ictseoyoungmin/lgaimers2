{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "273b75f6-25fa-4f9c-8c9d-fa33a985f2dd",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c415d9d-1111-46ed-bc2d-849c75ab962a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset,DataLoader,random_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "SEED =37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edae871a-b31b-4f06-bb88-0fd1f6660b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "seed_everything(SEED) # Seed 고정\n",
    "def norm(df):\n",
    "    df_normalized = (df - df.mean()) / (df.max() - df.min())\n",
    "    return df_normalized\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3301dd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfusionMatrix:\n",
    "  def __init__(self,classes = None):\n",
    "    self.cm = None\n",
    "   \n",
    "    if classes is not None:\n",
    "      self.classes = classes\n",
    "      self.n_classes = len(classes)\n",
    "\n",
    "  def get_conf_matrix(self,actual,pred):\n",
    "    if self.classes is None:\n",
    "      self.classes = torch.unique(actual)\n",
    "      self.n_classes = len(self.classes)\n",
    "    conf_matrix = torch.zeros((self.n_classes, self.n_classes), dtype=torch.int32)\n",
    "    for i in range(self.n_classes):\n",
    "        for j in range(self.n_classes):\n",
    "            conf_matrix[i, j] = torch.sum((actual == self.classes[i]) & (pred == self.classes[j]))\n",
    "\n",
    "    return conf_matrix\n",
    "\n",
    "  def update(self,actual,pred):\n",
    "\n",
    "    curr_cm = self.get_conf_matrix(actual,pred)\n",
    "    if self.cm is not None:\n",
    "      self.cm += curr_cm\n",
    "    else:\n",
    "      self.cm = curr_cm\n",
    "\n",
    "  def get_result(self):\n",
    "    return self.cm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "09e2b412",
   "metadata": {},
   "source": [
    "## Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "242a396a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self,in_features= 2884, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.embeding = nn.Conv1d(in_features,in_features,1,1,bias=False)\n",
    "        self.bn = nn.BatchNorm1d(in_features)\n",
    "        self.feature = nn.Sequential(\n",
    "                nn.Linear(in_features,in_features,False),\n",
    "                nn.BatchNorm1d(in_features),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(in_features,in_features//2,False),\n",
    "                nn.BatchNorm1d(in_features//2),\n",
    "                nn.ReLU(),\n",
    "                # nn.Dropout1d(0.5),\n",
    "                nn.Linear(in_features//2,in_features//8,False),\n",
    "                nn.BatchNorm1d(in_features//8),\n",
    "                nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.reg = nn.Sequential(\n",
    "            nn.Linear(in_features//8,in_features//32,False),\n",
    "            nn.BatchNorm1d(in_features//32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features//32,1,False),\n",
    "        )\n",
    "\n",
    "        self.clf = nn.Sequential(\n",
    "            nn.Linear(in_features//8,in_features//32,False),\n",
    "            nn.BatchNorm1d(in_features//32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features//32,num_classes,False),\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        # feature\n",
    "        x = x.view(-1,self.in_features,1)\n",
    "        x = self.embeding(x)\n",
    "        x = x.view(-1,self.in_features)\n",
    "        x = torch.sigmoid(self.bn(x))\n",
    "        x = self.feature(x)\n",
    "\n",
    "        out1 = self.reg(x)\n",
    "        out2 = self.clf(x)\n",
    "\n",
    "        return out1,out2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119f9c1c-39bc-42e7-a00d-3062d11b4f1e",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "64a1480e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv('./train.csv')\n",
    "# test_df = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ee76c413-001b-475e-9d1c-6662d25d2db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    \"\"\"\n",
    "        df : \n",
    "        train_df.PRODUCT_CODE.unique(),test_df.PRODUCT_CODE.unique()\n",
    "        >>> (array(['A_31', 'T_31', 'O_31'], dtype=object),\n",
    "            array(['T_31', 'A_31', 'O_31'], dtype=object))\n",
    "\n",
    "        a,b = train_df.LINE.unique() , test_df.LINE.unique()\n",
    "        a.sort()\n",
    "        b.sort()\n",
    "        a,b, a == b\n",
    "        >>> (array(['T010305', 'T010306', 'T050304', 'T050307', 'T100304', 'T100306'],\n",
    "            dtype=object),\n",
    "            array(['T010305', 'T010306', 'T050304', 'T050307', 'T100304', 'T100306'],\n",
    "            dtype=object),\n",
    "            array([ True,  True,  True,  True,  True,  True]))\n",
    "        df['LINE', 'PRODUCT_CODE']  values => onehot vector\n",
    "\n",
    "        onehot: y ['sparse','categorical']\n",
    "    \"\"\"\n",
    "    def __init__(self,train=True,onehot=True,y_qual=False):\n",
    "        super().__init__()\n",
    "        \n",
    "        self. train = train\n",
    "        self.y_qual = y_qual\n",
    "        if train:\n",
    "            self.df = pd.read_csv('./train.csv')\n",
    "        else:\n",
    "            self.df = pd.read_csv('./test.csv')\n",
    "        self.df = self.df.fillna(0)\n",
    "        qual_col = ['LINE', 'PRODUCT_CODE']\n",
    "\n",
    "        for i in qual_col:\n",
    "            col_names = [f'{i}_{j}' for j in range(len(self.df[i].unique()))]\n",
    "            onehot_matrix = self._onehot_encoder(self.df[i])\n",
    "            for k,col in enumerate(col_names):\n",
    "                self.df[col] = onehot_matrix[:,k]\n",
    "\n",
    "        if train:        \n",
    "            self.train_x = self.df.drop(columns=['PRODUCT_ID', 'TIMESTAMP', 'Y_Class', 'Y_Quality','LINE', 'PRODUCT_CODE']).to_numpy()\n",
    "            if onehot:\n",
    "                self.train_y = self._onehot_encoder(self.df['Y_Class'])\n",
    "                if y_qual:\n",
    "                    self.train_y = pd.concat((pd.DataFrame(self.train_y),self.df['Y_Quality']),axis=1).to_numpy()\n",
    "            else:\n",
    "                self.train_y = (self.df['Y_Class'])\n",
    "        else:\n",
    "            self.test_x = self.df.drop(columns=['PRODUCT_ID', 'TIMESTAMP','LINE', 'PRODUCT_CODE']).to_numpy()\n",
    "\n",
    "    def _onehot_encoder(self,scalar):\n",
    "        dic = {key:i for i,key in enumerate(np.sort(np.unique(scalar)))}\n",
    "        zeros = np.zeros((len(scalar),len(dic.keys())))\n",
    "        for i,s in enumerate(scalar.to_numpy()):\n",
    "            zeros[i,dic[s]] = 1\n",
    "        return zeros\n",
    "    \n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        return (self.train_x[index],self.train_y[index]) if self.train else self.test_x[index]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "def onehot_encoder(scalar:np.ndarray):\n",
    "    dic = {key:i for i,key in enumerate(np.sort(np.unique(scalar)))}\n",
    "    zeros = np.zeros((len(scalar),len(dic.keys())))\n",
    "    for i,s in enumerate(scalar.tolist()):\n",
    "        zeros[i][dic[s]] = 1\n",
    "    return zeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fec6b34-1e64-4d20-afdd-e96f4f77fa31",
   "metadata": {},
   "source": [
    "## Classification Model Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c6ca77bc-154c-4cb3-9251-3fe45d671416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "478 120\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "LR = 3e-1\n",
    "BATCH = 256\n",
    "\n",
    "dataset = Data(True,True,True)\n",
    "train_len = int(dataset.__len__() * 0.8)\n",
    "val_len = dataset.__len__() - train_len\n",
    "print(train_len,val_len)\n",
    "train_set,val_set = random_split(dataset,[train_len,val_len])\n",
    "train_loader = DataLoader(train_set,BATCH,True)\n",
    "val_loader = DataLoader(val_set,BATCH,False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3a12ac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for data in train_loader:\n",
    "#     x,y = data\n",
    "#     print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c09270ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FeatureExtractor()\n",
    "cirterion0 = nn.CrossEntropyLoss()\n",
    "cirterion1 = nn.MSELoss()\n",
    "# loss func에 y_quality 추가 가능성 있음\n",
    "optim = torch.optim.SGD(model.parameters(),LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b6acf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model,data_loader,device):\n",
    "    model.eval()\n",
    "    cm = ConfusionMatrix([0,1,2])\n",
    "    for data in (data_loader):\n",
    "        x,y = data\n",
    "        x = x.to(device).float()\n",
    "        y = y.to(device).float()\n",
    "        model.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = torch.softmax(model(x),1)\n",
    "        pred = torch.argmax(pred,1)\n",
    "        cm.update(torch.argmax(y,1),pred)\n",
    "    \n",
    "    pos = torch.sum(torch.Tensor([cm.cm[j,j] for j in range(3)]))\n",
    "    acc = pos/torch.sum(cm.cm)  \n",
    "    return acc  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4c000b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,data_loader,device,y_qual):\n",
    "    model.train()\n",
    "    train_loss = 0.\n",
    "    i=0\n",
    "    for data in (data_loader):\n",
    "        x,y = data\n",
    "        x = x.to(device).float()\n",
    "        y = y.to(device).float()\n",
    "        model.to(device)\n",
    "\n",
    "        if y_qual:    \n",
    "            y_clf,y_reg = y[:,:-1],y[:,-1]\n",
    "            print(y_clf.shape, y_reg.shape)\n",
    "            pred_reg,pred_clf = model(x)\n",
    "            print('re',pred_reg.shape,pred_clf.shape)\n",
    "            loss = cirterion0(pred_clf,y)+cirterion1(pred_reg.unsqueeze(0),y)\n",
    "        else:\n",
    "            pred = model(x)\n",
    "            loss = cirterion0(pred,y)\n",
    "\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        train_loss += loss.item()\n",
    "        i+=1\n",
    "    return model,train_loss/i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f69b1d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning(model,train_load,val_loader,device,y_qual):\n",
    "    train_losses=[]\n",
    "    val_scores = []\n",
    "    history = {}\n",
    "    for ep in range(EPOCHS):\n",
    "        model,train_loss = train(model,train_loader,device,y_qual)\n",
    "        print(f'{ep} epochs train loss : {train_loss:.5f}')\n",
    "        val_acc = eval(model,val_loader,device)\n",
    "        print(f'{ep} epochs val acc : {val_acc:.5f}')\n",
    "        train_losses.append(train_loss)\n",
    "        val_scores.append(val_acc)\n",
    "    history['train_loss'] = train_losses\n",
    "    history['val_acc'] = val_scores\n",
    "    \n",
    "    return model,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8f5006f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 3]) torch.Size([256])\n",
      "re torch.Size([256, 1]) torch.Size([256, 3])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "0D or 1D target tensor expected, multi-target not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model, history \u001b[39m=\u001b[39m learning(model,train_loader,val_loader,device,y_qual\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "Cell \u001b[1;32mIn[61], line 6\u001b[0m, in \u001b[0;36mlearning\u001b[1;34m(model, train_load, val_loader, device, y_qual)\u001b[0m\n\u001b[0;32m      4\u001b[0m history \u001b[39m=\u001b[39m {}\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m ep \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(EPOCHS):\n\u001b[1;32m----> 6\u001b[0m     model,train_loss \u001b[39m=\u001b[39m train(model,train_loader,device,y_qual)\n\u001b[0;32m      7\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mep\u001b[39m}\u001b[39;00m\u001b[39m epochs train loss : \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m:\u001b[39;00m\u001b[39m.5f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m     val_acc \u001b[39m=\u001b[39m \u001b[39meval\u001b[39m(model,val_loader,device)\n",
      "Cell \u001b[1;32mIn[60], line 16\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, data_loader, device, y_qual)\u001b[0m\n\u001b[0;32m     14\u001b[0m     pred_reg,pred_clf \u001b[39m=\u001b[39m model(x)\n\u001b[0;32m     15\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mre\u001b[39m\u001b[39m'\u001b[39m,pred_reg\u001b[39m.\u001b[39mshape,pred_clf\u001b[39m.\u001b[39mshape)\n\u001b[1;32m---> 16\u001b[0m     loss \u001b[39m=\u001b[39m cirterion0(pred_clf,y)\u001b[39m+\u001b[39mcirterion1(pred_reg\u001b[39m.\u001b[39munsqueeze(\u001b[39m0\u001b[39m),y)\n\u001b[0;32m     17\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     18\u001b[0m     pred \u001b[39m=\u001b[39m model(x)\n",
      "File \u001b[1;32mc:\\Users\\zxcas\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\zxcas\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\modules\\loss.py:1174\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1173\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m-> 1174\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mcross_entropy(\u001b[39minput\u001b[39;49m, target, weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight,\n\u001b[0;32m   1175\u001b[0m                            ignore_index\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mignore_index, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction,\n\u001b[0;32m   1176\u001b[0m                            label_smoothing\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_smoothing)\n",
      "File \u001b[1;32mc:\\Users\\zxcas\\anaconda3\\envs\\ml\\lib\\site-packages\\torch\\nn\\functional.py:3026\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3024\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3025\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3026\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: 0D or 1D target tensor expected, multi-target not supported"
     ]
    }
   ],
   "source": [
    "\n",
    "model, history = learning(model,train_loader,val_loader,device,y_qual=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ddaa38-bd6e-47d2-82d3-c000f188886a",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "a6a2df8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model,data_loader,device):\n",
    "    model.eval()\n",
    "    re = np.array([])\n",
    "    for data in (data_loader):\n",
    "        y = data\n",
    "        y = y.to(device).float()\n",
    "        model.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred = torch.softmax(model(y),1)\n",
    "        pred = torch.argmax(pred,1).cpu().numpy()\n",
    "        re = np.append(re,pred)\n",
    "    return re.reshape((-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "33b68656-3d7d-4221-b508-24d0d7622179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "test_data = Data(False)\n",
    "test_loader = DataLoader(test_data,BATCH,False)\n",
    "preds = infer(model,test_loader,device)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "fe09f809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "284\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(len(preds[preds ==i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97cf38e-2062-4645-9095-2ebac375711e",
   "metadata": {},
   "source": [
    "## Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "2d39dfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_datetime = datetime.now()\n",
    "formatted_datetime = current_datetime.strftime(\"%Y_%m_%d_%H_%M\")\n",
    "os.makedirs('./result',exist_ok=True)\n",
    "submit = pd.read_csv('./sample_submission.csv')\n",
    "submit['Y_Class'] = preds\n",
    "submit.to_csv(f'./result/baseline_submission_{formatted_datetime}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d85fa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f357decc5e2aff18a601b30d0bd2792b0c08acf56778473220cb87939fb94eb5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
