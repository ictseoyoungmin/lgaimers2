{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier #분류\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Downloading seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "     |████████████████████████████████| 292 kB 29.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.19.5)\n",
      "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.1.5)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.6/dist-packages (from seaborn) (3.3.4)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (8.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib>=2.2->seaborn) (1.15.0)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.11.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.5.2-py3-none-manylinux2014_x86_64.whl (173.6 MB)\n",
      "     |████████████████████████████████| 173.6 MB 16 kB/s               \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.19.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.4.1)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.5.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-3.3.5-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
      "     |████████████████████████████████| 2.0 MB 28.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.6/dist-packages (from lightgbm) (0.34.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.19.5)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in /usr/local/lib/python3.6/dist-packages (from lightgbm) (0.24.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lightgbm) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn!=0.22.0->lightgbm) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn!=0.22.0->lightgbm) (3.0.0)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-3.3.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading catboost-1.1.1-cp36-none-manylinux1_x86_64.whl (76.6 MB)\n",
      "     |████████████████████████████████| 76.6 MB 44 kB/s              \n",
      "\u001b[?25hCollecting plotly\n",
      "  Downloading plotly-5.13.1-py2.py3-none-any.whl (15.2 MB)\n",
      "     |████████████████████████████████| 15.2 MB 69.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.19.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from catboost) (1.4.1)\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.19.1-py3-none-any.whl (46 kB)\n",
      "     |████████████████████████████████| 46 kB 6.0 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from catboost) (1.1.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from catboost) (1.15.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from catboost) (3.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.0->catboost) (2021.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (8.4.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->catboost) (0.11.0)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: tenacity, plotly, graphviz, catboost\n",
      "Successfully installed catboost-1.1.1 graphviz-0.19.1 plotly-5.13.1 tenacity-8.2.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 37\n",
    "PROBAS = True\n",
    "FOLDS = 5\n",
    "N_ESTIMATORS = 1000\n",
    "TARGET = 'Y_Class'\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "seed_everything(SEED) # Seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./train.csv')\n",
    "test_df = pd.read_csv('./test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_df.drop(columns=['PRODUCT_ID', 'TIMESTAMP', 'Y_Class', 'Y_Quality'])\n",
    "train_y = train_df['Y_Class']\n",
    "\n",
    "test_x = test_df.drop(columns=['PRODUCT_ID', 'TIMESTAMP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test_df.drop(columns=['PRODUCT_ID', 'TIMESTAMP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.fillna(0)\n",
    "test_x = test_x.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이후 LINE과 product_code를 label encoding 해줍니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# qualitative to quantitative\n",
    "qual_col = ['LINE', 'PRODUCT_CODE']\n",
    "\n",
    "for i in qual_col:\n",
    "    le = LabelEncoder()\n",
    "    le = le.fit(train_x[i])\n",
    "    train_x[i] = le.transform(train_x[i])\n",
    "    \n",
    "    for label in np.unique(test_x[i]): \n",
    "        if label not in le.classes_: \n",
    "            le.classes_ = np.append(le.classes_, label)\n",
    "    test_x[i] = le.transform(test_x[i]) \n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습을 하기위해  train값 test값으로 나누어줍니다 \n",
    "# test_size는 0.15로 해야 결과값이 좋았다고 얘기해주면 좋을것같습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:(508, 2877) y_train: (508,)\n",
      "X_test:(90, 2877) y_test: (90,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_x, train_y, test_size = 0.15, random_state = 37)\n",
    "print (f'X_train:{X_train.shape} y_train: {y_train.shape}')\n",
    "print (f'X_test:{X_test.shape} y_test: {y_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 보시면 밑에 lgb_params, rf_params를 맞춰주기도 했는데\n",
    "# 기본값을 사용하는게 더 잘나와서 cl2,cl3,cl4를 보시면 사용하지 않을것을 볼수있습니다\n",
    "# catboost같은경우도 params를 지정해주지않은 결과값이 좋았기때문에 기본으로 사용하였음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "    'metric': 'cross_entropy',\n",
    "    'n_estimators': 10000,\n",
    "    'objective': 'softmax',\n",
    "    'learning_rate': 0.02,\n",
    "    'min_child_samples': 150,\n",
    "    'reg_alpha': 3e-5,\n",
    "    'reg_lambda': 9e-2,\n",
    "    'num_leaves': 20,\n",
    "    'max_depth': 16,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'subsample': 0.8,\n",
    "    'subsample_freq': 2,\n",
    "    'max_bin': 240,\n",
    "    'device': 'gpu'\n",
    "}\n",
    "\n",
    "rf_params = {\n",
    "    'max_depth': 7,\n",
    "    'min_samples_leaf': 10,\n",
    "    'random_state': 37\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl1 = KNeighborsClassifier(n_neighbors = 9)\n",
    "cl2 = RandomForestClassifier(**rf_params)\n",
    "cl3 = GaussianNB()\n",
    "cl4 = DecisionTreeClassifier()\n",
    "cl5 = CatBoostClassifier(task_type = 'GPU', verbose = None,logging_level = 'Silent')#task_type = 'GPU',verbose = None, \n",
    "cl6 = LGBMClassifier() \n",
    "cl7 = ExtraTreesClassifier(bootstrap=False, criterion='entropy', max_features=0.55, min_samples_leaf=8, min_samples_split=4, n_estimators=100) # Optimized using TPOT\n",
    "# cl8 = XGBClassifier(eval_metric='mlogloss', objective ='multi:softmax',use_label_encoder=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"RandomForest\": cl2,\n",
    "    \"DecisionTree\": cl4,\n",
    "    \"CatBoost\": cl5,\n",
    "    \"LGBM\": cl6,\n",
    "    \"ExtraTrees\": cl7,\n",
    "    # \"XGboost\":cl8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_scores_results, models_names = list(), list() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 그냥 기본 적으로 여러가지 방법으로 사용했을때의 결과값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Training started <<<<\n",
      "[RandomForest] - accuracy: 0.72050 \n",
      "[DecisionTree] - accuracy: 0.66123 \n",
      "[CatBoost] - accuracy: 0.77754 \n",
      "[LGBM] - accuracy: 0.77566 \n",
      "[ExtraTrees] - accuracy: 0.75585 \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\">>>> Training started <<<<\")\n",
    "for key in classifiers:\n",
    "    classifier = classifiers[key]\n",
    "    scores = cross_val_score(classifier, X_train, y_train, cv = FOLDS, scoring='accuracy')\n",
    "    models_scores_results.append(scores)\n",
    "    models_names.append(key)\n",
    "    print(\"[%s] - accuracy: %0.5f \" % (key, scores.mean()))\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # Save classifier for prediction \n",
    "    classifiers[key] = classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "959eeb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# >>>> Training started <<<<\n",
    "# [RandomForest] - accuracy: 0.72444 \n",
    "# [DecisionTree] - accuracy: 0.65343 \n",
    "# [CatBoost] - accuracy: 0.76968 \n",
    "# [LGBM] - accuracy: 0.76973 \n",
    "# [ExtraTrees] - accuracy: 0.74599 \n",
    "# [XGboost] - accuracy: 0.75201 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(models_scores_results, labels=models_names, showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 밑의 식 같은 경우는 5가지의 조합을 해봤을때의 결과값을 출력해보는 코드인데 \n",
    "# 하루 종일 돌려도 결과값이 다 안나와서 돌리다가 포기했습니다\n",
    "# 결과값: (제가 사진 올려드릴게요)  시간나면 돌려보겠습니다 \n",
    "# Total number of model combination: 26\n",
    "  1 - Stacked combination - Acc ('RandomForest', 'DecisionTree'): 0.73233\n",
    "  2 - Stacked combination - Acc ('RandomForest', 'CatBoost'): 0.74351\n",
    "  3 - Stacked combination - Acc ('RandomForest', 'LGBM'): 0.72863\n",
    "  4 - Stacked combination - Acc ('RandomForest', 'ExtraTrees'): 0.73607\n",
    "  5 - Stacked combination - Acc ('DecisionTree', 'CatBoost'): 0.73420\n",
    "  6 - Stacked combination - Acc ('DecisionTree', 'LGBM'): 0.73981\n",
    "  7 - Stacked combination - Acc ('DecisionTree', 'ExtraTrees'): 0.73046\n",
    "  8 - Stacked combination - Acc ('CatBoost', 'LGBM'): 0.73233\n",
    "  9 - Stacked combination - Acc ('CatBoost', 'ExtraTrees'): 0.73046\n",
    "  10 - Stacked combination - Acc ('LGBM', 'ExtraTrees'): 0.73794\n",
    "  11 - Stacked combination - Acc ('RandomForest', 'DecisionTree', 'CatBoost'): 0.78626\n",
    "  12 - Stacked combination - Acc ('RandomForest', 'DecisionTree', 'LGBM'): 0.78998\n",
    "  13 - Stacked combination - Acc ('RandomForest', 'DecisionTree', 'ExtraTrees'): 0.78811\n",
    "  14 - Stacked combination - Acc ('RandomForest', 'CatBoost', 'LGBM'): 0.78813\n",
    "  15 - Stacked combination - Acc ('RandomForest', 'CatBoost', 'ExtraTrees'): 0.78439\n",
    "  16 - Stacked combination - Acc ('RandomForest', 'LGBM', 'ExtraTrees'): 0.79185\n",
    "  17 - Stacked combination - Acc ('DecisionTree', 'CatBoost', 'LGBM'): 0.79000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "taken_classifiers = [\"RandomForest\", \"DecisionTree\", \"CatBoost\", \"LGBM\", \"ExtraTrees\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_stacking_search():\n",
    "    cls_list = []\n",
    "    best_auc = -1\n",
    "    i=0\n",
    "\n",
    "    best_cls_experiment = list()\n",
    "\n",
    "    print(\">>>> Training started <<<<\")\n",
    "\n",
    "    for cls_comb in range(2, len(taken_classifiers)+1):\n",
    "        for subset in itertools.combinations(taken_classifiers, cls_comb):\n",
    "            cls_list.append(subset)\n",
    "\n",
    "    print(f\"Total number of model combination: {len(cls_list)}\")\n",
    "\n",
    "    for cls_exp in cls_list:\n",
    "        cls_labels = list(cls_exp)\n",
    "\n",
    "        classifier_exp = []\n",
    "        for ii in range(len(cls_labels)):\n",
    "            label = taken_classifiers[ii]\n",
    "            classifier = classifiers[label]\n",
    "            classifier_exp.append(classifier)\n",
    "\n",
    "        sclf = StackingCVClassifier(classifiers = classifier_exp,\n",
    "                                    shuffle = False,\n",
    "                                    use_probas = True,\n",
    "                                    cv = FOLDS,\n",
    "                                    meta_classifier = mlr,\n",
    "                                    n_jobs = -1)\n",
    "\n",
    "        scores = cross_val_score(sclf, X_train, y_train, cv = FOLDS, scoring='accuracy')\n",
    "\n",
    "        if scores.mean() > best_auc:\n",
    "            best_cls_experiment = list(cls_exp)\n",
    "        i += 1\n",
    "        print(f\"  {i} - Stacked combination - Acc {cls_exp}: {scores.mean():.5f}\")\n",
    "        \n",
    "    return best_cls_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 밑의 permutationImportances는 각 모델이 중요하게 살펴보는 지표를 알려주는데 +에서 부터 -까지 나타나있습니다 \n",
    "# -같은경우는 결과값에 방해를 주기 때문에, 제외하고 너무 많은 column들을 지우게 되다보면 결과값에 영향을 미치게 되어서 0으로 나오는 column들도 포함할수 있도록 기준은 -0.001로 잡았습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a7f4cc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=CatBoostClassifier(silent=True, random_state=37).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm = PermutationImportance(model, random_state=37).fit(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_importance = -0.001\n",
    "mask = perm.feature_importances_ > minimum_importance\n",
    "features = X_train.columns[mask]\n",
    "X_train = X_train[features]\n",
    "X_test = X_test[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 돌려봤을때'LGBM',\"DecisionTree\",'CatBoost' 의 결과값이 좋았고 이를 이용해서 StackingCVClassifier로 파라미터 찾아주면서 가장 적절한 best모델을 top_meta_model이라고 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cls_experiment = [ 'LGBM',\"DecisionTree\",'CatBoost'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best models configuration: ['LGBM', 'DecisionTree', 'CatBoost']\n"
     ]
    }
   ],
   "source": [
    "print(f'The best models configuration: {best_cls_experiment}')\n",
    "\n",
    "classifier_exp = []\n",
    "for label in best_cls_experiment:\n",
    "        classifier = classifiers[label]\n",
    "        classifier_exp.append(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LGBMClassifier(),\n",
       " DecisionTreeClassifier(),\n",
       " <catboost.core.CatBoostClassifier at 0x2182fb562b0>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta model (slc) - accuracy: 0.77754 \n"
     ]
    }
   ],
   "source": [
    "scl = StackingCVClassifier(classifiers= classifier_exp,\n",
    "                            meta_classifier = mlr, # use meta-classifier\n",
    "                            use_probas = PROBAS,   # use_probas = True/False\n",
    "                            random_state = 37)\n",
    "\n",
    "scores = cross_val_score(scl, X_train, y_train, cv = FOLDS, scoring='accuracy')\n",
    "models_scores_results.append(scores)\n",
    "models_names.append('scl')\n",
    "print(\"Meta model (slc) - accuracy: %0.5f \" % (scores.mean()))\n",
    "scl.fit(X_train, y_train)\n",
    "\n",
    "top_meta_model = scl\n",
    "base_acc = scores.mean()\n",
    "# Meta model (slc) - accuracy: 0.78938 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta_best_params_search():\n",
    "\n",
    "    scl_params = {'meta_classifier__C': [0.001,0.01, 0.1, 1, 10, 14, 16]}\n",
    "\n",
    "    print(\">>>> Searching for best parameters started <<<<\")\n",
    "\n",
    "    grid = GridSearchCV(estimator=scl, \n",
    "                        param_grid= scl_params, \n",
    "                        cv=5,\n",
    "                        refit=True)\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    cv_keys = ('mean_test_score', 'std_test_score', 'params')\n",
    "\n",
    "    for r, _ in enumerate(grid.cv_results_['mean_test_score']):\n",
    "        print(\"%0.3f +/- %0.2f %r\" % (grid.cv_results_[cv_keys[0]][r], grid.cv_results_[cv_keys[1]][r] / 2.0, grid.cv_results_[cv_keys[2]][r]))\n",
    "\n",
    "    print('Best parameters: %s' % grid.best_params_)\n",
    "    print('Accuracy: %.5f' % grid.best_score_)\n",
    "    return grid, grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Searching for best parameters started <<<<\n",
      "0.675 +/- 0.00 {'meta_classifier__C': 0.001}\n",
      "0.675 +/- 0.00 {'meta_classifier__C': 0.01}\n",
      "0.772 +/- 0.01 {'meta_classifier__C': 0.1}\n",
      "0.793 +/- 0.01 {'meta_classifier__C': 1}\n",
      "0.783 +/- 0.01 {'meta_classifier__C': 10}\n",
      "0.789 +/- 0.01 {'meta_classifier__C': 14}\n",
      "0.776 +/- 0.01 {'meta_classifier__C': 16}\n",
      "Best parameters: {'meta_classifier__C': 1}\n",
      "Accuracy: 0.79334\n"
     ]
    }
   ],
   "source": [
    "hyper_meta_model, hyper_acc = meta_best_params_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6a4c44db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meta_classifier__C': 1}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyper_meta_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6b95ccef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2801"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7ef9277f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2877"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meta model (slc) - accuracy: 0.78348 \n"
     ]
    }
   ],
   "source": [
    "scl = StackingCVClassifier(classifiers= classifier_exp,\n",
    "                            meta_classifier = mlr, # use meta-classifier\n",
    "                            use_probas = PROBAS,   # use_probas = True/False\n",
    "                            random_state = 37)\n",
    "\n",
    "scores =cross_val_score(scl, X_train, y_train, cv = FOLDS, scoring='accuracy')\n",
    "models_scores_results.append(scores)\n",
    "models_names.append('scl')\n",
    "print(\"Meta model (slc) - accuracy: %0.5f \" % (scores.mean()))\n",
    "scl.fit(train_x[features], train_y)\n",
    "\n",
    "top_meta_model = scl\n",
    "base_acc = scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 이제 predict를 해줍니다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_meta_model = hyper_meta_model\n",
    "classifiers[\"scl\"] = top_meta_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_x = test_x[features]\n",
    "test_preds = classifiers['scl'].predict(test_x)[:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    261\n",
       "0     40\n",
       "2      9\n",
       "Name: Y_Class, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv('./sample_submission.csv')\n",
    "submission['Y_Class'] = test_preds\n",
    "submission['Y_Class'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('./extralgbmcatBoost_remove_test1.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7806f8e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    265\n",
       "0     38\n",
       "2      7\n",
       "Name: Y_Class, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1    265\n",
    "# 0     38\n",
    "# 2      7\n",
    "# Name: Y_Class, dtype: int64"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lg2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "7b4a77232de57f1a74ba645db038c4828a12e08da2dcf6af619cca0693c15199"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
